JMETER  Elasticsearch Tests 
-----------------------------

Performs ingestion, query , scroll queries at specified throughput and logs latencies on a CSV file 


Pre-requisites
---------------

Install Jmeter 3.0
Have a ES running cluster accessible

If planning to use the setup.bash script you need :
1.  npm
2.  coffeescript (see http://coffeescript.org/)


If planning to perform scan and scroll queries from Jmeter :
3. you need python 


Setup data and queries 
----------------------
* the ./input folder contains bulk indexing JSON files that can be generated by running the setup.bash (as a demo) That's where you need to put your bulk requests files that will be used by JMeter.
* If you want jmeter to send queries, there should be a query input csv (see format below) in ./queries
* If you want jmeter to sens scroll queries, there should be a scroll input csv (see format below) in ./queries



setup.bash
-----------
Use setup.bash script to setup sample apache logs located in ./ingest/logs.json.gz
This script will generate in ./input 20 BULK requests with 500 docs each.
tweak the parameters in the script to create more bulks



cleanup.bash
-------------
This script cleans up all files generated by the tests


test.bash
---------
Run this script to launch the tests
Modify the parameters in the file as follows :

JMETER_PATH : The path of your JMeter install
USER= Shield User
PASS= Shield Pass
HOST= Target Elastic hostname/ IP address
PORT= Target Elastic port (ex : 9200)
INDEX= Indices being queried (ex: apachelogs-* )
BULK_FILES= number of files in input (ex: 21)
QUERY_CSV= the file containing queries input  (ex:input1K1h.csv)
SCROLL_CSV=the file containing scroll input   (ex:inputScroll.csv) 

QUERY_THROUGHPUT= desired query throughput per minute (ex:5.0)
INDEX_THROUGHPUT=2.0
SCROLL_THROUGHPUT=20.0

elk_stress.jmx runs in the background and takes as additional params :
  -JtestScroll=true/false   : wether we enable the scroll queries to run during the test
  -JtestIngest=true/false   :  ""  ""     ""       ingestion "" "" 
  -JtestQuery=true/false    :   ""  ""    ""        querying 


* if ingestion enabled :
JMeter will iterate the files in ./input and send the bulk queries at specified throughput

* if scroll enabled :
JMeter will iterate the scroll CSV  and send scroll queries at specified throughput  

* if query enabled :
JMeter will iterate the scroll CSV  and send queries  at specified throughput  

* if shield not use then you have to disable the authentication managers in the Jmeter test plan. not tested  with an authentication manager without shield




* Format of the query input CSV :

elk_stress.jmx comes with a query inspired from a Kibana visualization that needs a time range, so it works well with the following format:
<timestamp time1>,<timestamp time2>,<query file name> body (in ./queries) ex:
  
time1,time2,queryFileName
1440348513990,1440352113990,query1.json

Note the variables time1, time2 referenced in the corresponding query1.json

You can refer to multiple queries in the CSV but make sure the CSV headers properly match each CSV values on each rows , ex:

time1,time2,param1,param2,queryFileName
1440348513990,1440352113990,,,query1.json
1440348513990,1440352113990,value1,value2,query2.json

Each query will be sent iteratively by JMeter, and the global throughput will be  QUERY_THROUGHPUT
  


* genDateIntervals.coffee can be used to generate random timestamp intervals.



* Feel free to add in the jmx other queries with their associated CSV input file  !



  
Test results
------------
Are located in results/results.csv
the latency in ms is the csv file


* todo
improve tooling 
write all scripts in python (nodeJs not always avail)
Send the latencies directly to ES when the HTTP API 


  
  

  
  
  



